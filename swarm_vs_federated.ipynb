{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d419c7",
   "metadata": {},
   "source": [
    "# Comparision of Swarm Learning and Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca616a29",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48dd7c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import torch\n",
    "import threading\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d14a7a9",
   "metadata": {},
   "source": [
    "## Define Blockchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f167e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block:\n",
    "    def __init__(self, round_num, leader_id, model_hash, previous_hash=\"\"):\n",
    "        self.round_num = round_num\n",
    "        self.leader_id = leader_id\n",
    "        self.model_hash = model_hash\n",
    "        self.previous_hash = previous_hash\n",
    "        self.timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        self.hash = self.calculate_hash()\n",
    "\n",
    "    def calculate_hash(self):\n",
    "        block_string = f\"{self.round_num}{self.leader_id}{self.model_hash}{self.previous_hash}{self.timestamp}\"\n",
    "        return hashlib.sha256(block_string.encode()).hexdigest()\n",
    "\n",
    "class Blockchain:\n",
    "    def __init__(self):\n",
    "        self.chain = [self.create_genesis_block()]\n",
    "\n",
    "    def create_genesis_block(self):\n",
    "        return Block(0, \"Genesis\", \"0\", \"0\")\n",
    "\n",
    "    def get_latest_block(self):\n",
    "        return self.chain[-1]\n",
    "\n",
    "    def add_block(self, new_block):\n",
    "        new_block.previous_hash = self.get_latest_block().hash\n",
    "        new_block.hash = new_block.calculate_hash()\n",
    "        self.chain.append(new_block)\n",
    "\n",
    "    def is_chain_valid(self):\n",
    "        for i in range(1, len(self.chain)):\n",
    "            current = self.chain[i]\n",
    "            previous = self.chain[i - 1]\n",
    "            if current.hash != current.calculate_hash() or current.previous_hash != previous.hash:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def display_chain(self, show_sample_params=False):\n",
    "        for block in self.chain:\n",
    "            print(\"\\n-----------------\")\n",
    "            print(f\"Round: {block.round_num}\")\n",
    "            print(f\"Leader ID: {block.leader_id}\")\n",
    "            print(f\"Model Parameter Hash: {block.model_hash}\")\n",
    "            print(f\"Previous Hash: {block.previous_hash}\")\n",
    "            print(f\"Timestamp: {block.timestamp}\")\n",
    "            print(f\"Block Hash: {block.hash}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a225addf",
   "metadata": {},
   "source": [
    "## Create Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "606a2c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, node_id, model, local_data, nodes, blockchain=None):\n",
    "        self.node_id = node_id\n",
    "        self.model = model\n",
    "        self.local_data = local_data\n",
    "        self.nodes = nodes\n",
    "        self.is_leader = False\n",
    "        self.active = True\n",
    "        self.blockchain = blockchain\n",
    "\n",
    "    def start_election(self):\n",
    "        leader_node = random.choice(self.nodes)\n",
    "        leader_node.become_leader()\n",
    "        return leader_node\n",
    "\n",
    "    def become_leader(self):\n",
    "        print(f\"Node {self.node_id} is now the leader.\")\n",
    "        self.is_leader = True\n",
    "        for node in self.nodes:\n",
    "            node.is_leader = node.node_id == self.node_id\n",
    "\n",
    "    def gather_parameters(self):\n",
    "        return train_local_model(self.local_data, self.model, epochs=1)\n",
    "\n",
    "    def verify_and_add_block(self, round_num, model_params):\n",
    "        model_params_serializable = {k: v.tolist() for k, v in model_params.items()}\n",
    "        model_hash = hashlib.sha256(json.dumps(model_params_serializable, sort_keys=True).encode()).hexdigest()\n",
    "        new_block = Block(round_num, self.node_id, model_hash, self.blockchain.get_latest_block().hash)\n",
    "        self.blockchain.add_block(new_block)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cbeea0",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41324f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(64 * 24 * 24, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34989fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_model(local_data, model, epochs=1):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in local_data:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaab8c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "711783b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_parameters(local_params_list):\n",
    "    global_params = {}\n",
    "    for key in local_params_list[0].keys():\n",
    "        global_params[key] = sum([params[key] for params in local_params_list]) / len(local_params_list)\n",
    "    return global_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69585745",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e61212e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "mnist_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "def split_data(dataset, num_nodes=3):\n",
    "    indices = list(range(len(dataset)))\n",
    "    random.shuffle(indices)\n",
    "    split_size = len(indices) // num_nodes\n",
    "    node_data_loaders = []\n",
    "    for i in range(num_nodes):\n",
    "        node_indices = indices[i * split_size: (i + 1) * split_size]\n",
    "        subset = Subset(dataset, node_indices)\n",
    "        loader = DataLoader(subset, batch_size=32, shuffle=True)\n",
    "        node_data_loaders.append(loader)\n",
    "    return node_data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15d12da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 3\n",
    "node_data_loaders = split_data(mnist_dataset, num_nodes=num_nodes)\n",
    "blockchain = Blockchain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba1f4e3",
   "metadata": {},
   "source": [
    "## Swarming Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "780e65e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swarm_learning_with_blockchain(swarm_nodes, blockchain, test_loader, num_rounds=5, epochs_per_round=3):\n",
    "    start_time = time.time()\n",
    "    accuracies = []\n",
    "    for round_num in range(num_rounds):\n",
    "        print(f\"\\n========== Swarm Round {round_num + 1}/{num_rounds} ==========\")\n",
    "        local_models = []\n",
    "        leader = swarm_nodes[0].start_election()\n",
    "\n",
    "        for node in swarm_nodes:\n",
    "            print(f\"Node {node.node_id} is training...\")\n",
    "            local_params = node.gather_parameters()\n",
    "            local_models.append(local_params)\n",
    "\n",
    "        if leader.is_leader and leader.active:\n",
    "            global_params = aggregate_parameters(local_models)\n",
    "            leader.verify_and_add_block(round_num, global_params)\n",
    "            for node in swarm_nodes:\n",
    "                node.model.load_state_dict(global_params)\n",
    "            accuracy = evaluate_model(leader.model, test_loader)\n",
    "            accuracies.append(accuracy)\n",
    "            print(f\"Round {round_num + 1} - Swarm Model Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    return total_time, avg_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d94a6af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm_nodes = []\n",
    "for i, data_loader in enumerate(node_data_loaders):\n",
    "    node = Node(i, CNNModel(), data_loader, [], blockchain)\n",
    "    swarm_nodes.append(node)\n",
    "for node in swarm_nodes:\n",
    "    node.nodes = swarm_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "942a32be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Swarm Learning...\n",
      "\n",
      "========== Swarm Round 1/10 ==========\n",
      "Node 2 is now the leader.\n",
      "Node 0 is training...\n",
      "Node 1 is training...\n",
      "Node 2 is training...\n",
      "Round 1 - Swarm Model Accuracy: 74.79%\n",
      "\n",
      "========== Swarm Round 2/10 ==========\n",
      "Node 0 is now the leader.\n",
      "Node 0 is training...\n",
      "Node 1 is training...\n",
      "Node 2 is training...\n",
      "Round 2 - Swarm Model Accuracy: 94.69%\n",
      "\n",
      "========== Swarm Round 3/10 ==========\n",
      "Node 1 is now the leader.\n",
      "Node 0 is training...\n",
      "Node 1 is training...\n",
      "Node 2 is training...\n",
      "Round 3 - Swarm Model Accuracy: 95.69%\n",
      "\n",
      "========== Swarm Round 4/10 ==========\n",
      "Node 0 is now the leader.\n",
      "Node 0 is training...\n",
      "Node 1 is training...\n",
      "Node 2 is training...\n",
      "Round 4 - Swarm Model Accuracy: 96.61%\n",
      "\n",
      "========== Swarm Round 5/10 ==========\n",
      "Node 0 is now the leader.\n",
      "Node 0 is training...\n",
      "Node 1 is training...\n",
      "Node 2 is training...\n",
      "Round 5 - Swarm Model Accuracy: 96.95%\n",
      "\n",
      "========== Swarm Round 6/10 ==========\n",
      "Node 2 is now the leader.\n",
      "Node 0 is training...\n",
      "Node 1 is training...\n",
      "Node 2 is training...\n",
      "Round 6 - Swarm Model Accuracy: 97.42%\n",
      "\n",
      "========== Swarm Round 7/10 ==========\n",
      "Node 0 is now the leader.\n",
      "Node 0 is training...\n",
      "Node 1 is training...\n",
      "Node 2 is training...\n",
      "Round 7 - Swarm Model Accuracy: 97.61%\n",
      "\n",
      "========== Swarm Round 8/10 ==========\n",
      "Node 2 is now the leader.\n",
      "Node 0 is training...\n",
      "Node 1 is training...\n",
      "Node 2 is training...\n",
      "Round 8 - Swarm Model Accuracy: 97.57%\n",
      "\n",
      "========== Swarm Round 9/10 ==========\n",
      "Node 0 is now the leader.\n",
      "Node 0 is training...\n",
      "Node 1 is training...\n",
      "Node 2 is training...\n",
      "Round 9 - Swarm Model Accuracy: 97.92%\n",
      "\n",
      "========== Swarm Round 10/10 ==========\n",
      "Node 2 is now the leader.\n",
      "Node 0 is training...\n",
      "Node 1 is training...\n",
      "Node 2 is training...\n",
      "Round 10 - Swarm Model Accuracy: 97.88%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRunning Swarm Learning...\")\n",
    "swarm_time, swarm_accuracy = swarm_learning_with_blockchain(swarm_nodes, blockchain, test_loader, num_rounds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22efa481",
   "metadata": {},
   "source": [
    "## Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6c062df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_learning(nodes, test_loader, num_rounds=5, epochs_per_round=3):\n",
    "    start_time = time.time()\n",
    "    accuracies = []\n",
    "    global_model = CNNModel()\n",
    "\n",
    "    for round_num in range(num_rounds):\n",
    "        print(f\"\\n========== Federated Round {round_num + 1}/{num_rounds} ==========\")\n",
    "        local_params_list = []\n",
    "\n",
    "        # Mỗi node huấn luyện cục bộ\n",
    "        for node in nodes:\n",
    "            print(f\"Node {node.node_id} is training...\")\n",
    "            local_model = CNNModel()\n",
    "            local_model.load_state_dict(global_model.state_dict())\n",
    "            local_params = train_local_model(node.local_data, local_model, epochs=epochs_per_round)\n",
    "            local_params_list.append(local_params)\n",
    "\n",
    "        # Tổng hợp tham số tại server trung tâm\n",
    "        global_params = aggregate_parameters(local_params_list)\n",
    "        global_model.load_state_dict(global_params)\n",
    "\n",
    "        # Đánh giá mô hình toàn cục\n",
    "        accuracy = evaluate_model(global_model, test_loader)\n",
    "        accuracies.append(accuracy)\n",
    "        print(f\"Round {round_num + 1} - Federated Model Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "    return total_time, avg_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "665b2fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Federated Learning...\n",
      "\n",
      "========== Federated Round 1/10 ==========\n",
      "Node 0 is training...\n",
      "Node 1 is training...\n",
      "Node 2 is training...\n",
      "Round 1 - Federated Model Accuracy: 96.37%\n",
      "\n",
      "========== Federated Round 2/10 ==========\n",
      "Node 0 is training...\n",
      "Node 1 is training...\n",
      "Node 2 is training...\n",
      "Round 2 - Federated Model Accuracy: 97.80%\n",
      "\n",
      "========== Federated Round 3/10 ==========\n",
      "Node 0 is training...\n",
      "Node 1 is training...\n",
      "Node 2 is training...\n",
      "Round 3 - Federated Model Accuracy: 98.23%\n",
      "\n",
      "========== Federated Round 4/10 ==========\n",
      "Node 0 is training...\n",
      "Node 1 is training...\n",
      "Node 2 is training...\n",
      "Round 4 - Federated Model Accuracy: 98.36%\n",
      "\n",
      "========== Federated Round 5/10 ==========\n",
      "Node 0 is training...\n",
      "Node 1 is training...\n",
      "Node 2 is training...\n",
      "Round 5 - Federated Model Accuracy: 98.45%\n",
      "\n",
      "========== Federated Round 6/10 ==========\n",
      "Node 0 is training...\n",
      "Node 1 is training...\n",
      "Node 2 is training...\n",
      "Round 6 - Federated Model Accuracy: 98.53%\n",
      "\n",
      "========== Federated Round 7/10 ==========\n",
      "Node 0 is training...\n",
      "Node 1 is training...\n",
      "Node 2 is training...\n",
      "Round 7 - Federated Model Accuracy: 98.54%\n",
      "\n",
      "========== Federated Round 8/10 ==========\n",
      "Node 0 is training...\n",
      "Node 1 is training...\n",
      "Node 2 is training...\n",
      "Round 8 - Federated Model Accuracy: 98.59%\n",
      "\n",
      "========== Federated Round 9/10 ==========\n",
      "Node 0 is training...\n",
      "Node 1 is training...\n",
      "Node 2 is training...\n",
      "Round 9 - Federated Model Accuracy: 98.70%\n",
      "\n",
      "========== Federated Round 10/10 ==========\n",
      "Node 0 is training...\n",
      "Node 1 is training...\n",
      "Node 2 is training...\n",
      "Round 10 - Federated Model Accuracy: 98.71%\n"
     ]
    }
   ],
   "source": [
    "federated_nodes = [Node(i, CNNModel(), data_loader, []) for i, data_loader in enumerate(node_data_loaders)]\n",
    "\n",
    "print(\"\\nRunning Federated Learning...\")\n",
    "federated_time, federated_accuracy = federated_learning(federated_nodes, test_loader, num_rounds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f531eae2",
   "metadata": {},
   "source": [
    "## Comparision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a1cd9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Comparison ==========\n",
      "Swarm Learning - Total Time: 324.29s, Average Accuracy: 94.71%\n",
      "Federated Learning - Total Time: 799.31s, Average Accuracy: 98.23%\n",
      "Time Difference (Swarm - Federated): -475.01s\n",
      "Accuracy Difference (Swarm - Federated): -3.52%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n========== Comparison ==========\")\n",
    "print(f\"Swarm Learning - Total Time: {swarm_time:.2f}s, Average Accuracy: {swarm_accuracy:.2f}%\")\n",
    "print(f\"Federated Learning - Total Time: {federated_time:.2f}s, Average Accuracy: {federated_accuracy:.2f}%\")\n",
    "print(f\"Time Difference (Swarm - Federated): {swarm_time - federated_time:.2f}s\")\n",
    "print(f\"Accuracy Difference (Swarm - Federated): {swarm_accuracy - federated_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
